# Gector_chinese
基于seq2edit (Gector)的中文文本纠错，既可以解决CSC任务（只能替换），也可以解决CGEC（除了替换，可以删除、添加）任务。

# 目录结构

```python
--src/：主代码
----gector/
--------checkpoints/：保存训练好的模型
--------logs/：保存日志
--------utils/：辅助文件
--------layers/：辅助网络层
--------data/：存放数据
------------ctc_vocab/：词表
------------sighan13/
------------sighan14/
------------sighan15/
------------sighan15_2/
------------midu2022/
------------cail2022/
--------tensorboard/
--------config.json：配置
--------model.py：模型
--------main.py：运行入口
--------evaluate.py：评估预测后的结果
--------dataset.py：处理数据为torch格式
--model_hub/：预训练模型
----chinese-bert-wwm-ext/：
--------vocab.txt
--------config.json
--------pytorch_model.bin
```

# 使用

这里以sighan15_2数据集为例：

- 1、将数据存放在data文件夹下并设置文件夹的名字，这里是sighan15_2。

- 2、在sighan15_2下新建一个process.py，该文件主要是用来得到train.json、test.json以及./ctc_vocab/ctc_correct_sighan15_2_tags.txt文件。其中train.json和test.jsonl里面的格式是：

	```python
	[
	    {
	        "id":"", 
	        "source":"错误文本",
	        "target":"正确文本",
	        "type":"positive or negative",
	    },
	    ......
	]
	```

	ctc_correct_sighan15_2_tags.txt里面是校正所需要的标签，根据数据而生成。可根据相关数据的实际情况自行修改。

- 3、在config.py里面新增该数据的相关路径，并修改data_name="sighan15_2"。

- 4、在main.py里面的data_mappin新增该数据集的信息，最后运行```python main.py```即可，训练完成后会在checkpoints/下会生成【数据名/模型名\_model.pt】。

- 5、main.py里面包含训练、验证、测试、预测单条、预测验证测试集并保存结果在【数据名\_results.json】里、对【数据名\_results.json】计算评价指标。

# 结果

```python
INFO:__main__:使用模型【roberta】，使用数据集：【sighan15_2】
INFO:__main__:训练集数据：3174条 验证集数据：1100条
INFO:__main__:使用【cuda】
INFO:utils.metric_utils:====== [Char Level] ======
INFO:utils.metric_utils:d_precsion:61.01%, d_recall:71.85000000000001%, d_f1:65.99000000000001%
INFO:utils.metric_utils:c_precsion:39.15%, c_recall:46.11%, c_f1:42.35%
INFO:utils.metric_utils:error_char_num: 540
{'loss': 16.299218118190765, 'c_precision': 0.3915, 'c_recall': 0.4611, 'c_f1': 0.4235, 'd_precision': 0.6101, 'd_recall': 0.7185, 'd_f1': 0.6599}
输入： 应为他学得很好，所以同班同学都喜欢问他问题。
输出： {'source': '应为他学得很好，所以同班同学都喜欢问他问题。', 'pred': '因为他学得很好，所以同班同学都喜欢问他问题。'}
====================================================================================================
输入： 我听说这个礼拜六你要开一个误会。可是那天我会很忙，因为我男朋友要回国来看我。
输出： {'source': '我听说这个礼拜六你要开一个误会。可是那天我会很忙，因为我男朋友要回国来看我。', 'pred': '我听说这个礼拜六你要开一个误会。可是那天我会很忙，因为我男朋友要回国来看我。'}
====================================================================================================
输入： 我以前想要高诉你，可是我忘了。我真户秃。
输出： {'source': '我以前想要高诉你，可是我忘了。我真户秃。', 'pred': '我以前想要高诉你，可是我忘了。我真漂道。'}
====================================================================================================
输入： 即然学生在学校老师的照顾下上课，他们的父母不需要一直看。
输出： {'source': '即然学生在学校老师的照顾下上课，他们的父母不需要一直看。', 'pred': '既然学生在学校老师的照顾下上课，他们的父母不需要一直看。'}
====================================================================================================
输入： 为了小孩的自由跟安全还有长大得很好，我完全还对我对某一所市立小学校长的建议「用网站看到小孩在教室里的情况」。
输出： {'source': '为了小孩的自由跟安全还有长大得很好，我完全还对我对某一所市立小学校长的建议「用网站看到小孩在教室里的情况」。', 'pred': '为了小孩的自由跟安全还有长大得很好，我完全还对我对某一所市立小学校长的建议「用网站看到小孩在教室里的情况」。'}
====================================================================================================
输入： 我觉得装了电影机是很好的作法，因为这机器有很多好处。
输出： {'source': '我觉得装了电影机是很好的作法，因为这机器有很多好处。', 'pred': '我觉得装了电影机是很好的做法，因为这机器有很多好处。'}
====================================================================================================
输入： 我看建设这种机器是很值得的事情，所有的学校已该建设。
输出： {'source': '我看建设这种机器是很值得的事情，所有的学校已该建设。', 'pred': '我看建设这种机器是很值得的事情，所有的学校已该建设。'}
====================================================================================================
输入： 看完那段文张，我是反对的
输出： {'source': '看完那段文张，我是反对的', 'pred': '看完那段文章，我是反对的'}
====================================================================================================
输入： 在三岁时，一场大火将家里烧得面目全飞
输出： {'source': '在三岁时，一场大火将家里烧得面目全飞', 'pred': '在三岁时，一场大火将家里烧得面目全飞'}
====================================================================================================
输入： 希望你生体好
输出： {'source': '希望你生体好', 'pred': '希望你身体好'}
====================================================================================================
输入： 感帽了
输出： {'source': '感帽了', 'pred': '感心了'}
====================================================================================================
输入： 你儿字今年几岁了
输出： {'source': '你儿字今年几岁了', 'pred': '你儿子今年几岁了'}
====================================================================================================
输入： 少先队员因该为老人让坐
输出： {'source': '少先队员因该为老人让坐', 'pred': '少先队员应该为老人让坐'}
====================================================================================================
输入： 随然今天很热
输出： {'source': '随然今天很热', 'pred': '突然今天很热'}
====================================================================================================
输入： 传然给我
输出： {'source': '传然给我', 'pred': '突然给我'}
====================================================================================================
输入： 呕土不止
输出： {'source': '呕土不止', 'pred': '呕土不止'}
====================================================================================================
输入： 哈蜜瓜
输出： {'source': '哈蜜瓜', 'pred': '哈蜜瓜'}
====================================================================================================
输入： 广州黄浦
输出： {'source': '广州黄浦', 'pred': '广州黄浦'}
====================================================================================================
输入： 在 上 上面 上面 那 什么 啊
输出： {'source': '在 上 上面 上面 那 什么 啊', 'pred': '在 上 上面 上面 那 什么 啊'}
====================================================================================================
输入： 呃 。 呃 ,啊,那用户名称是叫什么呢？
输出： {'source': '呃 。 呃 ,啊,那用户名称是叫什么呢？', 'pred': '呃 。 呃 ,啊,那用户名称是叫什么呢？'}
====================================================================================================
输入： 我生病了,咳数了好几天
输出： {'source': '我生病了,咳数了好几天', 'pred': '我生病了,咳书了好几天'}
====================================================================================================
输入： 对京东新人度大打折扣
输出： {'source': '对京东新人度大打折扣', 'pred': '对京东新人度大打折扣'}
====================================================================================================
输入： 我想买哥苹果手机
输出： {'source': '我想买哥苹果手机', 'pred': '我想买帮苹果手机'}
====================================================================================================
输入： #淮安消防[超话]#长夜漫漫，独愿汝安晚安[心]​​
输出： {'source': '#淮安消防[超话]#长夜漫漫，独愿汝安晚安[心]\u200b\u200b', 'pred': '#淮安消防[超话]#长夜漫漫，独愿有安晚安[心]\u200b\u200b'}
====================================================================================================
输入： 妻子遭国民党联保“打地雷公”的酷刑，生活无依无靠，沿村乞讨度日。
输出： {'source': '妻子遭国民党联保“打地雷公”的酷刑，生活无依无靠，沿村乞讨度日。', 'pred': '妻子遭国民党联保“打地雷工”的酷刑，生活无依无靠，沿村乞讨度日。'}
====================================================================================================
输入： 2.风力预报5日白天起风力逐渐加大，预计5～7日高海拔山区最大风力可达6～7级阵风8～9级。
输出： {'source': '2.风力预报5日白天起风力逐渐加大，预计5～7日高海拔山区最大风力可达6～7级阵风8～9级。', 'pred': '2.风力预报5日白天起风力逐渐加大，预计5～7日高海拔山区最大风力可达6～7级阵风8～9级。'}
====================================================================================================
INFO:utils.metric_utils:final f1:0.5636
INFO:utils.metric_utils:f1 logfile saved at:logs/f1_score.log
{'final_f1': 0.5636,
 'sentence_level:[correct_precision, correct_recall]': [0.3832684824902724,
                                                        0.3648148148148148],
 'sentence_level:f1': 0.3738,
 'token_level:[correct_precision, correct_recall, correct_f1] ': [0.3971061093247588,
                                                                  0.45740740740740743,
                                                                  0.4251],
 'token_level:[detect_precision, detect_recall, detect_f1]': [0.6141479099678456,
                                                              0.7074074074074074,
                                                              0.6575],
 'token_level:f1': 0.61102}
```

还是有一定的效果的，当然可能数据覆盖度不够，有些错误就难以纠正。

# 补充

- 1、针对于文本纠错而言，还是需要先找到一些额外的一些数据，通过数据增强的手段自己构造一些错误的数据。然后再在给定的数据集上利用训练数据进行微调，最后再在测试数据上进行预测和测试。
- 2、如果不自己生成【ctc_correct\_数据名_tags.txt】，可使用默认的ctc_correct\_tags.txt。

- 3、这里就不提供训练好的模型了，这里提供了数据，可自行训练。由于没有多卡，这里只是简单的单卡训练，没有用到分布式训练。

# 参考

> [destwang/CTC2021 (github.com)](https://github.com/destwang/CTC2021)
>
> [HillZhang1999/CTC-Report: CTC2021-中文文本纠错大赛的SOTA方案及在线演示 (github.com)](https://github.com/HillZhang1999/CTC-Report)
>
> [HillZhang1999/MuCGEC: MuCGEC中文纠错数据集及文本纠错SOTA模型开源；Code & Data for our NAACL 2022 Paper "MuCGEC: a Multi-Reference Multi-Source Evaluation Dataset for Chinese Grammatical Error Correction" (github.com)](https://github.com/HillZhang1999/MuCGEC)
>
> [CAIL (China AI and Law Challenge) Official website (cipsc.org.cn)](http://cail.cipsc.org.cn/task2.html?raceID=2&cail_tag=2022)
>
> [GECToR – Grammatical Error Correction: Tag, Not Rewrite](https://aclanthology.org/2020.bea-1.16/)
